{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOXcPXSPQKmU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixBkPBetQNNM"
      },
      "outputs": [],
      "source": [
        "data, info = tfds.load(\"imagenette/160px-v2\", with_info=True, as_supervised=True)\n",
        "train_data, valid_data = data['train'], data['validation']\n",
        "\n",
        "del data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuSgiaSd86jo"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_data.map(\n",
        "    lambda image, label: (tf.image.resize(image, (160, 160)), label))\n",
        "\n",
        "validation_dataset = valid_data.map(\n",
        "    lambda image, label: (tf.image.resize(image, (160, 160)), label)\n",
        ")\n",
        "\n",
        "del train_data\n",
        "del valid_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoMRYt189AYM",
        "outputId": "32240d63-5bec-4ea8-fe65-442753f971f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of classes in dataset is 10\n"
          ]
        }
      ],
      "source": [
        "num_classes = info.features['label'].num_classes\n",
        "print(f'Total number of classes in dataset is {num_classes}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCIah0yo9CaS",
        "outputId": "e6bef9e4-0011-4e67-9236-31cb44d9911a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Label 0 name is `n01440764`\n",
            "The Label 1 name is `n02102040`\n",
            "The Label 2 name is `n02979186`\n",
            "The Label 3 name is `n03000684`\n",
            "The Label 4 name is `n03028079`\n",
            "The Label 5 name is `n03394916`\n",
            "The Label 6 name is `n03417042`\n",
            "The Label 7 name is `n03425413`\n",
            "The Label 8 name is `n03445777`\n",
            "The Label 9 name is `n03888257`\n"
          ]
        }
      ],
      "source": [
        "get_label_name = info.features['label'].int2str\n",
        "text_labels = [get_label_name(i) for i in range(num_classes)]\n",
        "for idx,i in enumerate(text_labels):\n",
        "    print(f'The Label {idx} name is `{i}`')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIONi7JC9EU2",
        "outputId": "5f724048-e442-447e-c95c-346fe5fdc811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 23.9 s, sys: 5.18 s, total: 29 s\n",
            "Wall time: 31.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "X_train = list(map(lambda x: x[0], train_dataset))\n",
        "y_train = list(map(lambda x: x[1], train_dataset))\n",
        "\n",
        "\n",
        "X_valid = list(map(lambda x: x[0], validation_dataset))\n",
        "y_valid = list(map(lambda x: x[1], validation_dataset))\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, num_classes)\n",
        "\n",
        "del train_dataset\n",
        "del validation_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbT_13R69H3o",
        "outputId": "06867d6c-4f2b-4c65-ba7b-544e52d5bdb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size 9469 and Valid size 3925\n"
          ]
        }
      ],
      "source": [
        "train_len = info.splits['train'].num_examples\n",
        "valid_len = info.splits['validation'].num_examples\n",
        "print(f'Train size {train_len} and Valid size {valid_len}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb41rnU-9KHc",
        "outputId": "815a610b-8734-4785-ace6-fc558b24a8d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9469, 10), (3925, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "y_train.shape,y_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR7R5rDd9L5v",
        "outputId": "69e72aa5-4210-4a56-8eb6-f6b16ef4ad7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.34 s, sys: 851 ms, total: 3.19 s\n",
            "Wall time: 3.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      height_shift_range=0.2)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(\n",
        "      rescale=1./255)\n",
        "\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image.NumpyArrayIterator(\n",
        "    x=preprocess_input(np.array(X_train)), y=np.array(y_train), image_data_generator=train_datagen,batch_size=16\n",
        ")\n",
        "\n",
        "valid_ds = tf.keras.preprocessing.image.NumpyArrayIterator(\n",
        "    x=preprocess_input(np.array(X_valid)), y=np.array(y_valid), image_data_generator=valid_datagen,batch_size=32\n",
        ")\n",
        "\n",
        "# train_datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0hMLVkW9Rlu",
        "outputId": "fc14fe38-f422-4807-a367-bf9d3f45a615"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(592, 123)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_ds.__len__(),valid_ds.__len__() #depends on batching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvN_-GtP9VKq"
      },
      "outputs": [],
      "source": [
        "class CustomMLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        element_wise = tf.math.multiply_no_nan(x=y_true,\n",
        "                                                   y=tf.math.divide_no_nan(x=tf.math.subtract(x=y_true, y=y_pred), y=y_pred))\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))\n",
        "\n",
        "class CustomMFullLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        element_wise = tf.math.add(x=tf.math.divide_no_nan(x=tf.math.subtract(x=y_true, y=y_pred), y=y_pred),\n",
        "                           y=tf.math.divide_no_nan(x=tf.math.subtract(x=1.0, y=y_true), y=tf.math.subtract(x=1.0, y=y_pred)))\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))\n",
        "\n",
        "class CustomLLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        element_wise = tf.math.divide_no_nan(x=y_true,\n",
        "                                             y=tf.math.sqrt(\n",
        "                                                 x=tf.math.subtract(x=1.0,\n",
        "                                                                    y=tf.math.squared_difference(x=y_pred, y=1.0))\n",
        "                                             ))\n",
        "\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))\n",
        "\n",
        "class CustomLFullLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        element_wise = tf.math.subtract(x=tf.math.add(x=tf.math.divide_no_nan(x=y_true,\n",
        "                                             y=tf.math.sqrt(\n",
        "                                                 x=tf.math.subtract(x=1.0,\n",
        "                                                                    y=tf.math.squared_difference(x=y_pred, y=1.0))\n",
        "                                             )),\n",
        "                                                      y=tf.math.divide_no_nan(x=tf.math.subtract(x=1.0,y=y_true),\n",
        "                                                                              y=tf.math.sqrt(\n",
        "                                                                                  tf.math.subtract(x=1.0,y=tf.math.square(y_pred))\n",
        "                                                                              ))),\n",
        "                                        y=1.0)\n",
        "\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))\n",
        "\n",
        "class CE_Loss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        log_y_pred = tf.math.log(y_pred)\n",
        "        element_wise = -tf.math.multiply_no_nan(x=log_y_pred, y=y_true)\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))\n",
        "\n",
        "class ParabolicLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        element_wise = tf.math.multiply_no_nan(x=y_true,\n",
        "                                                   y=tf.math.subtract(x=1.0, y=tf.math.square(y_pred)))\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))\n",
        "\n",
        "class CircleLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        element_wise = tf.math.multiply_no_nan(x=y_true,\n",
        "                                                   y=tf.math.sqrt(tf.math.subtract(x=1.0, y=tf.math.square(y_pred))))\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))\n",
        "\n",
        "class CosLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        element_wise = tf.math.multiply_no_nan(y_true, tf.math.cos(tf.math.divide_no_nan(tf.math.multiply_no_nan(math.pi, y_pred), 2.0)))\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YKMorEZ9ZGB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "def create_model():\n",
        "    base_model = VGG19(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(160, 160, 3),\n",
        "        classes=10\n",
        "    )\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='tanh')(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGX4ovEMGxLT",
        "outputId": "e9874983-abe9-42c6-fd1a-3cb1e2b6bd5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function: Cross Entropy, Train Accuracy: 0.7384095191955566, Test Accuracy: 0.7785987257957458, Train Loss: 0.7384095191955566, Test Loss: 0.7785987257957458\n",
            "Loss function: Custom MLoss, Train Accuracy: 0.745907723903656, Test Accuracy: 0.7836942672729492, Train Loss: 0.745907723903656, Test Loss: 0.7836942672729492\n",
            "Loss function: Custom Full MLoss, Train Accuracy: 0.7478086352348328, Test Accuracy: 0.7880254983901978, Train Loss: 0.7478086352348328, Test Loss: 0.7880254983901978\n",
            "Loss function: Custom LLoss, Train Accuracy: 0.7435843348503113, Test Accuracy: 0.7839490175247192, Train Loss: 0.7435843348503113, Test Loss: 0.7839490175247192\n",
            "Loss function: Custom Full LLoss, Train Accuracy: 0.7550956010818481, Test Accuracy: 0.7946496605873108, Train Loss: 0.7550956010818481, Test Loss: 0.7946496605873108\n"
          ]
        }
      ],
      "source": [
        "losses = [CE_Loss(),CustomMLoss(),CustomMFullLoss(),CustomLLoss(),CustomLFullLoss()]\n",
        "names = [\"Cross Entropy\",\"Custom MLoss\",\"Custom Full MLoss\",\"Custom LLoss\",\"Custom Full LLoss\"]\n",
        "for i in range(len(losses)):\n",
        "    tf.keras.backend.clear_session()\n",
        "    loss_fn = losses[i]\n",
        "    model = create_model()\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss=loss_fn, metrics=[\"accuracy\"])\n",
        "    history = model.fit(train_ds, validation_data=valid_ds, epochs=10, verbose=0)\n",
        "    tr_loss, tr_acc = model.evaluate(train_ds, verbose=0)\n",
        "    ts_loss, ts_acc = model.evaluate(valid_ds, verbose=0)\n",
        "    print(\"Loss function: {0}, Train Accuracy: {1}, Test Accuracy: {2}, Train Loss: {1}, Test Loss: {2}\"\n",
        "    .format(names[i], tr_acc, ts_acc, tr_loss, ts_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUZGQuzievq1",
        "outputId": "4fb85d10-1031-4321-9f8b-a07fbcc2721b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntrain_loss, train_acc = model.evaluate(valid_ds, verbose=0)\\ntest_loss, test_acc = model.evaluate(valid_ds, verbose=0)\\nprint(f'The training accuracy was {round(train_acc,4)} and validation accuracy was {round(test_acc,4)} ')\\nprint(f'The training loss was {round(train_loss,4)} and validation loss was {round(test_loss,4)} ')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "'''\n",
        "train_loss, train_acc = model.evaluate(valid_ds, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(valid_ds, verbose=0)\n",
        "print(f'The training accuracy was {round(train_acc,4)} and validation accuracy was {round(test_acc,4)} ')\n",
        "print(f'The training loss was {round(train_loss,4)} and validation loss was {round(test_loss,4)} ')\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}