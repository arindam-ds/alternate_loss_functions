{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qt9-FlJEsaK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(1234)\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import pickle\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "zD7jsOhYGYbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels1 = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels1 = tf.keras.utils.to_categorical(test_labels)"
      ],
      "metadata": {
        "id": "W6Yzf3QWtQT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels1))\n",
        "train_ds = train_ds.shuffle(train_images.shape[0]).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels1))\n",
        "test_ds = train_ds.shuffle(test_images.shape[0]).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "cY7WJKqxtHuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        element_wise = tf.math.multiply_no_nan(x=y_true,\n",
        "                                                   y=tf.math.divide_no_nan(x=tf.math.subtract(x=y_true, y=y_pred), y=y_pred))\n",
        "        #element_wise = tf.math.add(x=tf.math.divide_no_nan(x=tf.math.subtract(x=y_true, y=y_pred), y=y_pred),\n",
        "        #                   y=tf.math.divide_no_nan(x=tf.math.subtract(x=1.0, y=y_true), y=tf.math.subtract(x=1.0, y=y_pred)))\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))\n",
        "\n",
        "class CustomLLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        element_wise = tf.math.divide_no_nan(x=y_true,\n",
        "                                             y=tf.math.sqrt(\n",
        "                                                 x=tf.math.subtract(x=1.0,\n",
        "                                                                    y=tf.math.squared_difference(x=y_pred, y=1.0))\n",
        "                                             ))\n",
        "\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))\n",
        "\n",
        "class CustomLFullLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        element_wise = tf.math.subtract(x=tf.math.add(x=tf.math.divide_no_nan(x=y_true,\n",
        "                                             y=tf.math.sqrt(\n",
        "                                                 x=tf.math.subtract(x=1.0,\n",
        "                                                                    y=tf.math.squared_difference(x=y_pred, y=1.0))\n",
        "                                             )),\n",
        "                                                      y=tf.math.divide_no_nan(x=tf.math.subtract(x=1.0,y=y_true),\n",
        "                                                                              y=tf.math.sqrt(\n",
        "                                                                                  tf.math.subtract(x=1.0,y=tf.math.square(y_pred))\n",
        "                                                                              ))),\n",
        "                                        y=1.0)\n",
        "\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))\n",
        "\n",
        "class My_CE_Loss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def call(self, y_true, y_pred):\n",
        "        log_y_pred = tf.math.log(y_pred)\n",
        "        element_wise = -tf.math.multiply_no_nan(x=log_y_pred, y=y_true)\n",
        "        return tf.reduce_mean(tf.reduce_sum(element_wise,axis=1))\n"
      ],
      "metadata": {
        "id": "sUgiSuiKGZAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "base_model = VGG19(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(32, 32, 3),\n",
        "    classes=10\n",
        ")\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='tanh')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "opt = Adam(learning_rate=1e-5)\n",
        "model.compile(optimizer=opt, loss=CustomMLoss(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NeSbBoYhGbrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
        "    resize = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n",
        "\n",
        "    base_model_output = tf.keras.applications.vgg16.VGG16(\n",
        "        include_top=False,\n",
        "        input_shape=(224, 224, 3),\n",
        "        weights='imagenet'\n",
        "    )(resize)\n",
        "\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model_output)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
        "    predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=predictions)\n",
        "    return model"
      ],
      "metadata": {
        "id": "xc3ZcNl7lIY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss=CustomMLoss(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "history = model.fit(train_ds, epochs=50, verbose=2)"
      ],
      "metadata": {
        "id": "RhxDVP3ixPBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kf7zaLiWOcOX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}